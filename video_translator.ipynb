{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy5V0_d2X_6c",
        "outputId": "66e7e37c-ac26-4cea-daee-cad6e43d1aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 63 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spleeter --quiet"
      ],
      "metadata": {
        "id": "YkNc8Z6Y3iBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "4DfiuLEZnqN0",
        "outputId": "25dd86da-4ce8-4381-baa6-933276ae7523"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-891e29f1-8f65-4f77-abbf-907968e319b1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-891e29f1-8f65-4f77-abbf-907968e319b1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving forest_song.mp4 to forest_song.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "import os\n",
        "\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "video = VideoFileClip(file_name)\n",
        "audio = video.audio\n",
        "\n",
        "base_folder_name = os.path.splitext(file_name)[0]\n",
        "os.makedirs(base_folder_name, exist_ok=True)"
      ],
      "metadata": {
        "id": "te-4f5CQnmnE"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_FOLDER_NAME = base_folder_name\n",
        "AUDIO_WAV = f\"{BASE_FOLDER_NAME}/extracted_audio.wav\"\n",
        "OUTPUT_SEPARATE_AUDIO_DIR = f\"{BASE_FOLDER_NAME}/separated_audio\"\n",
        "OUTPUT_SEGMENTS_DIR = f\"{BASE_FOLDER_NAME}/segments\"\n",
        "TRANSLATED_RESULTS = f\"{BASE_FOLDER_NAME}/transcription_results.json\"\n",
        "OUTPUT_DIR_CLONED = f\"{BASE_FOLDER_NAME}/cloned_voices\"\n",
        "VOICES = f\"{OUTPUT_SEPARATE_AUDIO_DIR}/voices.wav\"\n",
        "BACKGROUND = f\"{OUTPUT_SEPARATE_AUDIO_DIR}/background.wav\"\n",
        "PRE_VOICE_DIR = f\"{BASE_FOLDER_NAME}/pre_voice\""
      ],
      "metadata": {
        "id": "-Gy3JkazqDH4"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio.write_audiofile(AUDIO_WAV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsPZDgkNqThJ",
        "outputId": "ff01636a-b29d-4433-f723-3641e87302d1"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in forest_song/extracted_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                      "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spleeter.separator import Separator\n",
        "from spleeter.audio.adapter import AudioAdapter\n",
        "import soundfile as sf\n",
        "import os\n",
        "\n",
        "separator = Separator('spleeter:2stems')\n",
        "\n",
        "audio_loader = AudioAdapter.default()\n",
        "waveform, sr = audio_loader.load(AUDIO_WAV, sample_rate=44100)\n",
        "prediction = separator.separate(waveform)\n",
        "\n",
        "os.makedirs(OUTPUT_SEPARATE_AUDIO_DIR, exist_ok=True)\n",
        "\n",
        "sf.write(VOICES, prediction[\"vocals\"], sr)\n",
        "sf.write(f\"{OUTPUT_SEPARATE_AUDIO_DIR}/background.wav\", prediction[\"accompaniment\"], sr)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1iQlRWhH-O7k"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyannote.audio --quiet\n",
        "!pip install pydub  --quiet"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9yNutQ82G18A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71af0be0-3351-4d3e-e7e2-0a00e565e550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [typer]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.13.2 which is incompatible.\n",
            "gradio-client 1.8.0 requires httpx>=0.24.1, but you have httpx 0.19.0 which is incompatible.\n",
            "descript-audiotools 0.7.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
            "gradio 5.23.0 requires httpx>=0.24.1, but you have httpx 0.19.0 which is incompatible.\n",
            "spleeter 2.4.2 requires typer<0.4.0,>=0.3.2, but you have typer 0.16.0 which is incompatible.\n",
            "openai 1.81.0 requires httpx<1,>=0.23.0, but you have httpx 0.19.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.1 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.38 which is incompatible.\n",
            "google-genai 1.16.1 requires anyio<5.0.0,>=4.8.0, but you have anyio 3.7.1 which is incompatible.\n",
            "google-genai 1.16.1 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.19.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.1 which is incompatible.\n",
            "orbax-checkpoint 0.11.13 requires jax>=0.5.0, but you have jax 0.4.38 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.1 which is incompatible.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyannote.audio import Pipeline\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import torch\n",
        "from typing import List, Tuple\n",
        "\n",
        "input_audio_path = VOICES\n",
        "\n",
        "use_cuda = True\n",
        "pause_duration_ms = 500\n",
        "min_segment_duration_ms = 500\n",
        "max_pause_ms = 1000\n",
        "\n",
        "pipeline = Pipeline.from_pretrained(\n",
        "    \"pyannote/speaker-diarization-3.1\",\n",
        "    use_auth_token=\"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\"\n",
        ")\n",
        "\n",
        "if use_cuda:\n",
        "    pipeline.to(torch.device(\"cuda\"))\n",
        "\n",
        "full_audio = AudioSegment.from_wav(input_audio_path)\n",
        "diarization = pipeline(input_audio_path)\n",
        "os.makedirs(OUTPUT_SEGMENTS_DIR, exist_ok=True)\n",
        "pause = AudioSegment.silent(duration=pause_duration_ms)\n",
        "\n",
        "def group_segments(diarization) -> List[Tuple[int, int, str]]:\n",
        "    grouped = []\n",
        "    last_speaker = None\n",
        "    last_start, last_end = None, None\n",
        "\n",
        "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "        start_ms = int(turn.start * 1000)\n",
        "        end_ms = int(turn.end * 1000)\n",
        "\n",
        "        if (\n",
        "            speaker == last_speaker and\n",
        "            last_end is not None and\n",
        "            start_ms - last_end <= max_pause_ms\n",
        "        ):\n",
        "            last_end = max(last_end, end_ms)\n",
        "        else:\n",
        "            if last_speaker is not None:\n",
        "                grouped.append((last_start, last_end, last_speaker))\n",
        "            last_speaker = speaker\n",
        "            last_start = start_ms\n",
        "            last_end = end_ms\n",
        "\n",
        "    if last_speaker is not None:\n",
        "        grouped.append((last_start, last_end, last_speaker))\n",
        "\n",
        "    return grouped\n",
        "\n",
        "segments = group_segments(diarization)\n",
        "\n",
        "for i, (start_ms, end_ms, speaker) in enumerate(segments):\n",
        "    duration_ms = end_ms - start_ms\n",
        "\n",
        "    if duration_ms < min_segment_duration_ms:\n",
        "        print(f\"Skip short {i} {speaker} ({duration_ms} ms)\")\n",
        "        continue\n",
        "\n",
        "    segment_audio = full_audio[start_ms:end_ms]\n",
        "    final_audio = pause + segment_audio + pause\n",
        "\n",
        "    filename = os.path.join(OUTPUT_SEGMENTS_DIR, f\"{i:03d}_{speaker}_st{start_ms}_et{end_ms}.wav\")\n",
        "    final_audio.export(filename, format=\"wav\")\n",
        "    print(f\"Saved : {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIZ4bdBkaCwt",
        "outputId": "6f7199cd-89c0-46a7-8c15-643b53ca84f8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1808.)\n",
            "  std = sequences.std(dim=-1, correction=1)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved : forest_song/segments/000_SPEAKER_00_st655_et4350.wav\n",
            "Skip short 1 SPEAKER_00 (489 ms)\n",
            "Saved : forest_song/segments/002_SPEAKER_00_st8620_et10189.wav\n",
            "Saved : forest_song/segments/003_SPEAKER_00_st11792_et14205.wav\n",
            "Saved : forest_song/segments/004_SPEAKER_00_st15269_et16365.wav\n",
            "Saved : forest_song/segments/005_SPEAKER_00_st18340_et19977.wav\n",
            "Skip short 6 SPEAKER_02 (185 ms)\n",
            "Skip short 7 SPEAKER_00 (237 ms)\n",
            "Saved : forest_song/segments/008_SPEAKER_02_st24044_et27419.wav\n",
            "Skip short 9 SPEAKER_00 (389 ms)\n",
            "Saved : forest_song/segments/010_SPEAKER_02_st28718_et31215.wav\n",
            "Skip short 11 SPEAKER_00 (34 ms)\n",
            "Skip short 12 SPEAKER_02 (17 ms)\n",
            "Saved : forest_song/segments/013_SPEAKER_00_st31789_et33612.wav\n",
            "Saved : forest_song/segments/014_SPEAKER_03_st34236_et38742.wav\n",
            "Saved : forest_song/segments/015_SPEAKER_01_st41982_et44277.wav\n",
            "Skip short 16 SPEAKER_03 (405 ms)\n",
            "Skip short 17 SPEAKER_00 (51 ms)\n",
            "Skip short 18 SPEAKER_02 (354 ms)\n",
            "Skip short 19 SPEAKER_00 (270 ms)\n",
            "Skip short 20 SPEAKER_02 (34 ms)\n",
            "Saved : forest_song/segments/021_SPEAKER_01_st45779_et49778.wav\n",
            "Saved : forest_song/segments/022_SPEAKER_02_st50183_et56494.wav\n",
            "Saved : forest_song/segments/023_SPEAKER_03_st56899_et58637.wav\n",
            "Saved : forest_song/segments/024_SPEAKER_02_st57810_et59059.wav\n",
            "Saved : forest_song/segments/025_SPEAKER_03_st59447_et60105.wav\n",
            "Saved : forest_song/segments/026_SPEAKER_02_st60224_et63379.wav\n",
            "Saved : forest_song/segments/027_SPEAKER_03_st65404_et70349.wav\n",
            "Saved : forest_song/segments/028_SPEAKER_01_st71614_et72542.wav\n",
            "Saved : forest_song/segments/029_SPEAKER_01_st73774_et78921.wav\n",
            "Saved : forest_song/segments/030_SPEAKER_03_st79410_et87257.wav\n",
            "Saved : forest_song/segments/031_SPEAKER_01_st86616_et87595.wav\n",
            "Skip short 32 SPEAKER_03 (422 ms)\n",
            "Saved : forest_song/segments/033_SPEAKER_01_st89046_et94176.wav\n",
            "Saved : forest_song/segments/034_SPEAKER_01_st95543_et96370.wav\n",
            "Saved : forest_song/segments/035_SPEAKER_01_st105634_et111389.wav\n",
            "Skip short 36 SPEAKER_03 (16 ms)\n",
            "Skip short 37 SPEAKER_01 (34 ms)\n",
            "Skip short 38 SPEAKER_03 (101 ms)\n",
            "Skip short 39 SPEAKER_01 (17 ms)\n",
            "Skip short 40 SPEAKER_03 (68 ms)\n",
            "Saved : forest_song/segments/041_SPEAKER_01_st112249_et112975.wav\n",
            "Skip short 42 SPEAKER_03 (17 ms)\n",
            "Saved : forest_song/segments/043_SPEAKER_01_st114865_et119134.wav\n",
            "Saved : forest_song/segments/044_SPEAKER_02_st121986_et125901.wav\n",
            "Saved : forest_song/segments/045_SPEAKER_00_st127352_et134727.wav\n",
            "Skip short 46 SPEAKER_00 (354 ms)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git --quiet\n",
        "!pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git --quiet\n",
        "!sudo apt update && sudo apt install ffmpeg  --quiet\n",
        "!pip install deep-translator --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb-nP4XTUC7I",
        "outputId": "ab9bb2a0-11c4-4187-d141-281fce2eb2d5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:4 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Ign:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,564 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,264 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,552 kB]\n",
            "Fetched 9,764 kB in 1min 8s (144 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "67 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 67 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from deep_translator import GoogleTranslator\n",
        "import json\n",
        "\n",
        "whisper_model = whisper.load_model(\"turbo\")\n",
        "translator = GoogleTranslator(source='auto', target='en')"
      ],
      "metadata": {
        "id": "gsPf3RqRVwJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e33b89-0000-434f-ca04-e15d1b9dc1a0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "os.makedirs(OUTPUT_SEGMENTS_DIR, exist_ok=True)\n",
        "\n",
        "audio_files = []\n",
        "for file_name in os.listdir(OUTPUT_SEGMENTS_DIR):\n",
        "    if file_name.endswith(\".wav\"):\n",
        "        index = int(file_name.split(\"_\")[0])\n",
        "        audio_files.append((index, file_name))\n",
        "\n",
        "audio_files.sort()\n",
        "\n",
        "results = []\n",
        "for index, file_name in audio_files:\n",
        "    file_path = os.path.join(OUTPUT_SEGMENTS_DIR, file_name)\n",
        "    speaker = \"_\".join(file_name.replace(\".wav\", \"\").split(\"_\")[1:])\n",
        "\n",
        "    result = whisper_model.transcribe(\n",
        "        file_path,\n",
        "        language=\"uk\",\n",
        "        temperature=0.6,\n",
        "        condition_on_previous_text=True\n",
        "    )\n",
        "\n",
        "    text = result['text']\n",
        "    translated = GoogleTranslator(source=\"uk\", target=\"en\").translate(text)\n",
        "\n",
        "    results.append({\n",
        "        \"index\": index,\n",
        "        \"speaker\": speaker,\n",
        "        \"file_path\": file_path,\n",
        "        \"text\": text,\n",
        "        \"translated\": translated\n",
        "    })\n",
        "\n",
        "    print(f\"[{index}] {speaker}: {text} | {translated}\")\n",
        "\n",
        "with open(TRANSLATED_RESULTS, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results, f, ensure_ascii=False, indent=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke6ADV-2UBqd",
        "outputId": "a57a46c2-5b78-4191-f7cb-d063951e4ddd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] SPEAKER_00_st655_et4350:  Час тобі нарешті дізнатись усю правду. | It's time for you to finally find out all the truth.\n",
            "[2] SPEAKER_00_st8620_et10189:  Безліч зимтений. | Many winter.\n",
            "[3] SPEAKER_00_st11792_et14205:  Битву ще зроби на людей. | Do the battle for people.\n",
            "[4] SPEAKER_00_st15269_et16365:  та лисових миш | and bald mouse\n",
            "[5] SPEAKER_00_st18340_et19977:  Запеклими ворога! | Fierce enemy!\n",
            "[8] SPEAKER_02_st24044_et27419:  Вітаю, мене звуть Лукаш. Тут сказано, ви добре платите. | Congratulations, my name is Lukash. It is said here you pay well.\n",
            "[10] SPEAKER_02_st28718_et31215:  Не марнує гроші на мене. | Does not waste money on me.\n",
            "[13] SPEAKER_00_st31789_et33612:  Старого дідугана! | Old grandfather!\n",
            "[14] SPEAKER_03_st34236_et38742:  Ну а робити власне що? Відшукай дерево. З отаким листю. | Well, to do what? Find the tree. With such leaves.\n",
            "[15] SPEAKER_01_st41982_et44277:  Люди у лісі? Не може. | People in the forest? Can't.\n",
            "[21] SPEAKER_01_st45779_et49778:  Годі кланявкати про лісовий закон. Його давно пора змінити. | It is not necessary to clan about forest law. It is time to change it.\n",
            "[22] SPEAKER_02_st50183_et56494:  Кажуть, що в хащах за Чорною Герою мавки-чорнявки і русалки-спокусниці можуть до смерті залоскодати. | It is said that in the thickets behind the black hero, the mawki-blacks and mermaids can be pledged to death.\n",
            "[23] SPEAKER_03_st56899_et58637:  Підіди дейблежте! | Unders Diebuzhzha!\n",
            "[24] SPEAKER_02_st57810_et59059:  Хайдешті. | Hidest.\n",
            "[25] SPEAKER_03_st59447_et60105:  Гроброго! | The grab!\n",
            "[26] SPEAKER_02_st60224_et63379:  І ти такий, смієсься, смієсься, отудить. | And you are, laughing, laughing, he will be so.\n",
            "[27] SPEAKER_03_st65404_et70349:  Що ж вам завадило? Білочки? Метелики? Чи може лісова нечість? | What prevented you? Squirrels? Butterflies? Can forest uncleanness?\n",
            "[28] SPEAKER_01_st71614_et72542:  Дякую за перегляд! | Thank you for watching!\n",
            "[29] SPEAKER_01_st73774_et78921:  Я не лісова нечість. Я мавка. Душа пролісу. | I am not a forest uncleanness. I am Mavka. The soul of the snowdrop.\n",
            "[30] SPEAKER_03_st79410_et87257:  Не вірю, що цей плебейз порожніми руками повернувся. Я знав, що всі смертні жальні навідники, підманували. | I do not believe that this plebeis has returned empty hands. I knew that all the mortal feasting gunners, they were hugged.\n",
            "[31] SPEAKER_01_st86616_et87595:  Физмана улафи | Fizana Ulafi\n",
            "[33] SPEAKER_01_st89046_et94176:  Але вони подарували мені те, чого я раніше не відчувала. | But they gave me what I didn't feel before.\n",
            "[34] SPEAKER_01_st95543_et96370:  Йоєй! | Yoy!\n",
            "[35] SPEAKER_01_st105634_et111389:  Твоя музика в справжній магії? Запускайте ви всю лісу! | Your music is in real magic? Run you all the forest!\n",
            "[41] SPEAKER_01_st112249_et112975:  Хія! | Him!\n",
            "[43] SPEAKER_01_st114865_et119134:  Я в серці мою те, що не вмирає. | I am in my heart my thing that doesn't die.\n",
            "[44] SPEAKER_02_st121986_et125901:  Єдина магія, яку ми люди маємо, це любов. | The only magic we have people we have is love.\n",
            "[45] SPEAKER_00_st127352_et134727:  Ні, нехай свистеть, русалки надійно заховають його в лісі. Один з мотоцок тут, другий з мотоцок там. | No, let it whistle, mermaids securely hide it in the forest. One of the motots here, the other of the mototsok there.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U pip --quiet\n",
        "! pip install TTS --quiet"
      ],
      "metadata": {
        "id": "PXhazcQoyfsI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from TTS.api import TTS\n",
        "import torch.serialization\n",
        "import os\n",
        "\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import XttsAudioConfig, XttsArgs\n",
        "from TTS.config.shared_configs import BaseDatasetConfig\n",
        "\n",
        "torch.serialization.add_safe_globals([\n",
        "    XttsConfig,\n",
        "    XttsAudioConfig,\n",
        "    BaseDatasetConfig,\n",
        "    XttsArgs\n",
        "])\n",
        "\n",
        "device = \"cuda\"\n",
        "#tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
        "tts = TTS(\"tts_models/en/ljspeech/tacotron2-DDC\").to(device)"
      ],
      "metadata": {
        "id": "QehvTaPtycDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "8ea985cc-4dce-4fbe-fdf5-fff89da04a12"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=map_location, **kwargs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
            " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
            " > Using model: Tacotron2\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:False\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:8000.0\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:2.718281828459045\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > Model's reduction rate `r` is set to: 1\n",
            " > Vocoder Model: hifigan\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:False\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:8000.0\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:False\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:2.718281828459045\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > Generator Model: hifigan_generator\n",
            " > Discriminator Model: hifigan_discriminator\n",
            "Removing weight norm...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "with open(TRANSLATED_RESULTS, \"r\", encoding=\"utf-8\") as f:\n",
        "    texts = json.load(f)\n",
        "\n",
        "os.makedirs(PRE_VOICE_DIR, exist_ok=True)\n",
        "\n",
        "for item in texts:\n",
        "   text = item[\"translated\"]\n",
        "   speaker = item[\"speaker\"]\n",
        "   index = item[\"index\"]\n",
        "   output_path = os.path.join(PRE_VOICE_DIR, f\"{index}.wav\")\n",
        "\n",
        "   tts.tts_to_file(text=text,file_path=output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49efes2Gu2lD",
        "outputId": "3baeeb41-76b2-43e6-df4f-ecfe2f632be5",
        "collapsed": true
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Text splitted to sentences.\n",
            "[\"It's time for you to finally find out all the truth.\"]\n",
            " > Processing time: 0.38399410247802734\n",
            " > Real-time factor: 0.09960321334039741\n",
            " > Text splitted to sentences.\n",
            "['Many winter.']\n",
            " > Processing time: 0.1295793056488037\n",
            " > Real-time factor: 0.09069399725609834\n",
            " > Text splitted to sentences.\n",
            "['Do the battle for people.']\n",
            " > Processing time: 0.17777252197265625\n",
            " > Real-time factor: 0.092765148369393\n",
            " > Text splitted to sentences.\n",
            "['and bald mouse']\n",
            " > Processing time: 0.16274428367614746\n",
            " > Real-time factor: 0.07961731130322709\n",
            " > Text splitted to sentences.\n",
            "['Fierce enemy!']\n",
            " > Processing time: 0.15015459060668945\n",
            " > Real-time factor: 0.09575742488655432\n",
            " > Text splitted to sentences.\n",
            "['Congratulations, my name is Lukash.', 'It is said here you pay well.']\n",
            " > Processing time: 0.6355762481689453\n",
            " > Real-time factor: 0.10586216062458638\n",
            " > Text splitted to sentences.\n",
            "['Does not waste money on me.']\n",
            " > Processing time: 0.24359893798828125\n",
            " > Real-time factor: 0.09894187633807841\n",
            " > Text splitted to sentences.\n",
            "['Old grandfather!']\n",
            " > Processing time: 0.18125414848327637\n",
            " > Real-time factor: 0.09458192857952111\n",
            " > Text splitted to sentences.\n",
            "['Well, to do what?', 'Find the tree.', 'With such leaves.']\n",
            " > Processing time: 0.6206631660461426\n",
            " > Real-time factor: 0.11156272671283948\n",
            " > Text splitted to sentences.\n",
            "['People in the forest?', \"Can't.\"]\n",
            " > Processing time: 0.27993130683898926\n",
            " > Real-time factor: 0.08368336924891151\n",
            " > Text splitted to sentences.\n",
            "['It is not necessary to clan about forest law.', 'It is time to change it.']\n",
            " > Processing time: 0.5389771461486816\n",
            " > Real-time factor: 0.09729864809223893\n",
            " > Text splitted to sentences.\n",
            "['It is said that in the thickets behind the black hero, the mawki-blacks and mermaids can be pledged to death.']\n",
            " > Processing time: 0.7587742805480957\n",
            " > Real-time factor: 0.10258862016877704\n",
            " > Text splitted to sentences.\n",
            "['Unders Diebuzhzha!']\n",
            " > Processing time: 0.14461898803710938\n",
            " > Real-time factor: 0.07981699755251957\n",
            " > Text splitted to sentences.\n",
            "['Hidest.']\n",
            " > Processing time: 0.13033437728881836\n",
            " > Real-time factor: 0.09508579338335246\n",
            " > Text splitted to sentences.\n",
            "['The grab!']\n",
            " > Processing time: 0.08748602867126465\n",
            " > Real-time factor: 0.0684648967987431\n",
            " > Text splitted to sentences.\n",
            "['And you are, laughing, laughing, he will be so.']\n",
            " > Processing time: 0.5419948101043701\n",
            " > Real-time factor: 0.1044228432371152\n",
            " > Text splitted to sentences.\n",
            "['What prevented you?', 'Squirrels?', 'Butterflies?', 'Can forest uncleanness?']\n",
            " > Processing time: 0.7262892723083496\n",
            " > Real-time factor: 0.10102113477997016\n",
            " > Text splitted to sentences.\n",
            "['Thank you for watching!']\n",
            " > Processing time: 0.18280339241027832\n",
            " > Real-time factor: 0.09481592968212828\n",
            " > Text splitted to sentences.\n",
            "['I am not a forest uncleanness.', 'I am Mavka.', 'The soul of the snowdrop.']\n",
            " > Processing time: 0.6493396759033203\n",
            " > Real-time factor: 0.0959030372794195\n",
            " > Text splitted to sentences.\n",
            "['I do not believe that this plebeis has returned empty hands.', 'I knew that all the mortal feasting gunners, they were hugged.']\n",
            " > Processing time: 0.8096191883087158\n",
            " > Real-time factor: 0.09321273549606926\n",
            " > Text splitted to sentences.\n",
            "['Fizana Ulafi']\n",
            "   > Decoder stopped with `max_decoder_steps` 10000\n",
            " > Processing time: 12.690964698791504\n",
            " > Real-time factor: 0.10877716034158685\n",
            " > Text splitted to sentences.\n",
            "[\"But they gave me what I didn't feel before.\"]\n",
            " > Processing time: 0.33234500885009766\n",
            " > Real-time factor: 0.10006837782860845\n",
            " > Text splitted to sentences.\n",
            "['Yoy!']\n",
            " > Processing time: 0.09447479248046875\n",
            " > Real-time factor: 0.08560031123415253\n",
            " > Text splitted to sentences.\n",
            "['Your music is in real magic?', 'Run you all the forest!']\n",
            " > Processing time: 0.432633638381958\n",
            " > Real-time factor: 0.08976561771983377\n",
            " > Text splitted to sentences.\n",
            "['Him!']\n",
            " > Processing time: 0.0993645191192627\n",
            " > Real-time factor: 0.09830346583721027\n",
            " > Text splitted to sentences.\n",
            "[\"I am in my heart my thing that doesn't die.\"]\n",
            " > Processing time: 0.37372708320617676\n",
            " > Real-time factor: 0.10449231822753345\n",
            " > Text splitted to sentences.\n",
            "['The only magic we have people we have is love.']\n",
            " > Processing time: 2.122257709503174\n",
            " > Real-time factor: 0.10269079055893618\n",
            " > Text splitted to sentences.\n",
            "['No, let it whistle, mermaids securely hide it in the forest.', 'One of the motots here, the other of the mototsok there.']\n",
            " > Processing time: 0.9233705997467041\n",
            " > Real-time factor: 0.0969760789343032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Plachtaa/seed-vc.git  --quiet"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2vBv9JsK014K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r seed-vc/requirements.txt  --quiet"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WYjgLMpyLHzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade protobuf  --quiet"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PrdtjHZ2Sy7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p configs/v2\n",
        "!wget -O configs/v2/vc_wrapper.yaml https://raw.githubusercontent.com/Plachtaa/seed-vc/main/configs/v2/vc_wrapper.yaml"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cGUH6ClUXhmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "with open(TRANSLATED_RESULTS, \"r\") as f:\n",
        "    segments = json.load(f)\n",
        "output_dir = OUTPUT_DIR_CLONED\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for segment in segments:\n",
        "    speaker = segment[\"speaker\"]\n",
        "    target_wav = segment[\"file_path\"]\n",
        "    index = segment[\"index\"]\n",
        "    out_name = os.path.splitext(os.path.basename(target_wav))[0]\n",
        "    out_path = os.path.join(output_dir, f\"{out_name}_cloned.wav\")\n",
        "    source_path = os.path.join(PRE_VOICE_DIR, f\"{index}.wav\")\n",
        "\n",
        "    command_v1 = [\n",
        "        \"python\", \"seed-vc/inference.py\",\n",
        "        \"--source\", source_path,\n",
        "        \"--target\", target_wav,\n",
        "        \"--output\", output_dir,\n",
        "        \"--diffusion-steps\", \"70\",\n",
        "        \"--length-adjust\", \"1.0\",\n",
        "        \"--inference-cfg-rat\", \"0.7\",\n",
        "        \"--f0-condition\", \"False\",\n",
        "        \"--auto-f0-adjust\", \"True\",\n",
        "        \"--semi-tone-shift\", \"0\",\n",
        "        \"--fp16\", \"True\"\n",
        "    ]\n",
        "\n",
        "    command_v2 = [\n",
        "        \"python\", \"seed-vc/inference_v2.py\",\n",
        "        \"--source\", source_path,\n",
        "        \"--target\", target_wav,\n",
        "        \"--output\", output_dir,\n",
        "        \"--diffusion-steps\", \"50\",\n",
        "        \"--intelligibility-cfg-rate\", \"0.7\",\n",
        "        \"--similarity-cfg-rate\", \"0.8\",\n",
        "        \"--convert-style\", \"True\",\n",
        "        \"--anonymization-only\", \"False\",\n",
        "        \"--top-p\", \"0.9\",\n",
        "        \"--temperature\", \"0.5\",\n",
        "        \"--repetition-penalty\", \"1.3\"\n",
        "    ]\n",
        "\n",
        "    print(f\"🔄 Converting: {target_wav} → {source_path}\")\n",
        "    subprocess.run(command_v1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-qVHGmUbiJj",
        "outputId": "42ba08e6-4915-4986-8039-95d2221f4ba6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Converting: forest_song/segments/000_SPEAKER_00_st655_et4350.wav → forest_song/pre_voice/0.wav\n",
            "🔄 Converting: forest_song/segments/002_SPEAKER_00_st8620_et10189.wav → forest_song/pre_voice/2.wav\n",
            "🔄 Converting: forest_song/segments/003_SPEAKER_00_st11792_et14205.wav → forest_song/pre_voice/3.wav\n",
            "🔄 Converting: forest_song/segments/004_SPEAKER_00_st15269_et16365.wav → forest_song/pre_voice/4.wav\n",
            "🔄 Converting: forest_song/segments/005_SPEAKER_00_st18340_et19977.wav → forest_song/pre_voice/5.wav\n",
            "🔄 Converting: forest_song/segments/008_SPEAKER_02_st24044_et27419.wav → forest_song/pre_voice/8.wav\n",
            "🔄 Converting: forest_song/segments/010_SPEAKER_02_st28718_et31215.wav → forest_song/pre_voice/10.wav\n",
            "🔄 Converting: forest_song/segments/013_SPEAKER_00_st31789_et33612.wav → forest_song/pre_voice/13.wav\n",
            "🔄 Converting: forest_song/segments/014_SPEAKER_03_st34236_et38742.wav → forest_song/pre_voice/14.wav\n",
            "🔄 Converting: forest_song/segments/015_SPEAKER_01_st41982_et44277.wav → forest_song/pre_voice/15.wav\n",
            "🔄 Converting: forest_song/segments/021_SPEAKER_01_st45779_et49778.wav → forest_song/pre_voice/21.wav\n",
            "🔄 Converting: forest_song/segments/022_SPEAKER_02_st50183_et56494.wav → forest_song/pre_voice/22.wav\n",
            "🔄 Converting: forest_song/segments/023_SPEAKER_03_st56899_et58637.wav → forest_song/pre_voice/23.wav\n",
            "🔄 Converting: forest_song/segments/024_SPEAKER_02_st57810_et59059.wav → forest_song/pre_voice/24.wav\n",
            "🔄 Converting: forest_song/segments/025_SPEAKER_03_st59447_et60105.wav → forest_song/pre_voice/25.wav\n",
            "🔄 Converting: forest_song/segments/026_SPEAKER_02_st60224_et63379.wav → forest_song/pre_voice/26.wav\n",
            "🔄 Converting: forest_song/segments/027_SPEAKER_03_st65404_et70349.wav → forest_song/pre_voice/27.wav\n",
            "🔄 Converting: forest_song/segments/028_SPEAKER_01_st71614_et72542.wav → forest_song/pre_voice/28.wav\n",
            "🔄 Converting: forest_song/segments/029_SPEAKER_01_st73774_et78921.wav → forest_song/pre_voice/29.wav\n",
            "🔄 Converting: forest_song/segments/030_SPEAKER_03_st79410_et87257.wav → forest_song/pre_voice/30.wav\n",
            "🔄 Converting: forest_song/segments/031_SPEAKER_01_st86616_et87595.wav → forest_song/pre_voice/31.wav\n",
            "🔄 Converting: forest_song/segments/033_SPEAKER_01_st89046_et94176.wav → forest_song/pre_voice/33.wav\n",
            "🔄 Converting: forest_song/segments/034_SPEAKER_01_st95543_et96370.wav → forest_song/pre_voice/34.wav\n",
            "🔄 Converting: forest_song/segments/035_SPEAKER_01_st105634_et111389.wav → forest_song/pre_voice/35.wav\n",
            "🔄 Converting: forest_song/segments/041_SPEAKER_01_st112249_et112975.wav → forest_song/pre_voice/41.wav\n",
            "🔄 Converting: forest_song/segments/043_SPEAKER_01_st114865_et119134.wav → forest_song/pre_voice/43.wav\n",
            "🔄 Converting: forest_song/segments/044_SPEAKER_02_st121986_et125901.wav → forest_song/pre_voice/44.wav\n",
            "🔄 Converting: forest_song/segments/045_SPEAKER_00_st127352_et134727.wav → forest_song/pre_voice/45.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import re\n",
        "\n",
        "base = AudioSegment.from_wav(BACKGROUND)\n",
        "\n",
        "directory = output_dir\n",
        "\n",
        "def extract_vc_number(filename):\n",
        "    match = re.match(r\"vc_(\\d+)_\", filename)\n",
        "    return int(match.group(1)) if match else float('inf')\n",
        "\n",
        "def get_start_time(filename):\n",
        "    match = re.search(r\"_st(\\d+)\", filename)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return None\n",
        "\n",
        "def get_end_time(filename):\n",
        "    match = re.search(r\"_et(\\d+)\", filename)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return None\n",
        "\n",
        "wav_files = sorted(\n",
        "    [f for f in os.listdir(directory) if f.endswith(\".wav\")],\n",
        "    key=extract_vc_number\n",
        ")\n",
        "\n",
        "for file_name in wav_files:\n",
        "    print(f\"Process: {file_name}\")\n",
        "    start_ms = get_start_time(file_name)\n",
        "    end_ms = get_end_time(file_name)\n",
        "\n",
        "    file_path = os.path.join(directory, file_name)\n",
        "    segment = AudioSegment.from_wav(file_path)\n",
        "\n",
        "    target_duration = end_ms - start_ms\n",
        "    actual_duration = len(segment)\n",
        "\n",
        "    padding = AudioSegment.silent(duration=(start_ms + len(segment)) - len(base))\n",
        "    base += padding\n",
        "    base = base.overlay(segment, position=start_ms)\n",
        "\n",
        "base.export(f\"{BASE_FOLDER_NAME}/result.wav\", format=\"wav\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "M1t30LrP2b20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ada088e-eaa5-413e-e18c-c9d5bacb538b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process: vc_0_000_SPEAKER_00_st655_et4350_1.0_70_0.7.wav\n",
            "Process: vc_2_002_SPEAKER_00_st8620_et10189_1.0_70_0.7.wav\n",
            "Process: vc_3_003_SPEAKER_00_st11792_et14205_1.0_70_0.7.wav\n",
            "Process: vc_4_004_SPEAKER_00_st15269_et16365_1.0_70_0.7.wav\n",
            "Process: vc_5_005_SPEAKER_00_st18340_et19977_1.0_70_0.7.wav\n",
            "Process: vc_8_008_SPEAKER_02_st24044_et27419_1.0_70_0.7.wav\n",
            "Process: vc_10_010_SPEAKER_02_st28718_et31215_1.0_70_0.7.wav\n",
            "Process: vc_13_013_SPEAKER_00_st31789_et33612_1.0_70_0.7.wav\n",
            "Process: vc_14_014_SPEAKER_03_st34236_et38742_1.0_70_0.7.wav\n",
            "Process: vc_15_015_SPEAKER_01_st41982_et44277_1.0_70_0.7.wav\n",
            "Process: vc_21_021_SPEAKER_01_st45779_et49778_1.0_70_0.7.wav\n",
            "Process: vc_22_022_SPEAKER_02_st50183_et56494_1.0_70_0.7.wav\n",
            "Process: vc_23_023_SPEAKER_03_st56899_et58637_1.0_70_0.7.wav\n",
            "Process: vc_24_024_SPEAKER_02_st57810_et59059_1.0_70_0.7.wav\n",
            "Process: vc_25_025_SPEAKER_03_st59447_et60105_1.0_70_0.7.wav\n",
            "Process: vc_26_026_SPEAKER_02_st60224_et63379_1.0_70_0.7.wav\n",
            "Process: vc_27_027_SPEAKER_03_st65404_et70349_1.0_70_0.7.wav\n",
            "Process: vc_28_028_SPEAKER_01_st71614_et72542_1.0_70_0.7.wav\n",
            "Process: vc_29_029_SPEAKER_01_st73774_et78921_1.0_70_0.7.wav\n",
            "Process: vc_30_030_SPEAKER_03_st79410_et87257_1.0_70_0.7.wav\n",
            "Process: vc_31_031_SPEAKER_01_st86616_et87595_1.0_70_0.7.wav\n",
            "Process: vc_33_033_SPEAKER_01_st89046_et94176_1.0_70_0.7.wav\n",
            "Process: vc_34_034_SPEAKER_01_st95543_et96370_1.0_70_0.7.wav\n",
            "Process: vc_35_035_SPEAKER_01_st105634_et111389_1.0_70_0.7.wav\n",
            "Process: vc_41_041_SPEAKER_01_st112249_et112975_1.0_70_0.7.wav\n",
            "Process: vc_43_043_SPEAKER_01_st114865_et119134_1.0_70_0.7.wav\n",
            "Process: vc_44_044_SPEAKER_02_st121986_et125901_1.0_70_0.7.wav\n",
            "Process: vc_45_045_SPEAKER_00_st127352_et134727_1.0_70_0.7.wav\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='forest_song/result.wav'>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "\n",
        "audio = AudioFileClip(f\"{BASE_FOLDER_NAME}/result.wav\")\n",
        "\n",
        "final_video = video.set_audio(audio)\n",
        "output_video = f\"{BASE_FOLDER_NAME}/{BASE_FOLDER_NAME}_cloned.mp4\"\n",
        "final_video.write_videofile(output_video, audio_codec=\"aac\")\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download(output_video)"
      ],
      "metadata": {
        "id": "LIpWEMR1_lRK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "31db3bfa-8222-4cd1-d431-393557054b06"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video forest_song/forest_song_cloned.mp4.\n",
            "MoviePy - Writing audio in forest_song_clonedTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video forest_song/forest_song_cloned.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready forest_song/forest_song_cloned.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1483533a-3a75-4874-aaa5-7e059c4f65ff\", \"forest_song_cloned.mp4\", 8785601)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}